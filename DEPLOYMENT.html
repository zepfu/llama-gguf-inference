

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Deployment Guide &mdash; llama-gguf-inference 1.0.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=9edc463e" />

  
      <script src="_static/jquery.js?v=5d32c60e"></script>
      <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="_static/documentation_options.js?v=8d563738"></script>
      <script src="_static/doctools.js?v=fd6eb6e6"></script>
      <script src="_static/sphinx_highlight.js?v=6ffebe34"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Migration Guide" href="MIGRATION.html" />
    <link rel="prev" title="Configuration Guide" href="CONFIGURATION.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            llama-gguf-inference
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">User Guides:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="API_REFERENCE.html">API Reference</a><ul>
<li class="toctree-l2"><a class="reference internal" href="API_REFERENCE.html#public-endpoints">Public Endpoints</a><ul>
<li class="toctree-l3"><a class="reference internal" href="API_REFERENCE.html#get-ping">GET /ping</a></li>
<li class="toctree-l3"><a class="reference internal" href="API_REFERENCE.html#get-health">GET /health</a></li>
<li class="toctree-l3"><a class="reference internal" href="API_REFERENCE.html#get-metrics">GET /metrics</a><ul>
<li class="toctree-l4"><a class="reference internal" href="API_REFERENCE.html#json-format-default">JSON format (default)</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="AUTHENTICATION.html">Authentication Guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="AUTHENTICATION.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="AUTHENTICATION.html#quick-start">Quick Start</a><ul>
<li class="toctree-l3"><a class="reference internal" href="AUTHENTICATION.html#create-api-keys-file">1. Create API Keys File</a></li>
<li class="toctree-l3"><a class="reference internal" href="AUTHENTICATION.html#enable-authentication">2. Enable Authentication</a></li>
<li class="toctree-l3"><a class="reference internal" href="AUTHENTICATION.html#make-authenticated-requests">3. Make Authenticated Requests</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="AUTHENTICATION.html#configuration">Configuration</a><ul>
<li class="toctree-l3"><a class="reference internal" href="AUTHENTICATION.html#environment-variables">Environment Variables</a></li>
<li class="toctree-l3"><a class="reference internal" href="AUTHENTICATION.html#keys-file-format">Keys File Format</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="AUTHENTICATION.html#key-management">Key Management</a><ul>
<li class="toctree-l3"><a class="reference internal" href="AUTHENTICATION.html#key-management-cli">Key Management CLI</a></li>
<li class="toctree-l3"><a class="reference internal" href="AUTHENTICATION.html#manual-key-generation">Manual Key Generation</a></li>
<li class="toctree-l3"><a class="reference internal" href="AUTHENTICATION.html#add-new-key-manual">Add New Key (Manual)</a></li>
<li class="toctree-l3"><a class="reference internal" href="AUTHENTICATION.html#rotate-key-manual">Rotate Key (Manual)</a></li>
<li class="toctree-l3"><a class="reference internal" href="AUTHENTICATION.html#revoke-key">Revoke Key</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="AUTHENTICATION.html#endpoint-access">Endpoint Access</a><ul>
<li class="toctree-l3"><a class="reference internal" href="AUTHENTICATION.html#public-endpoints-no-auth-required">Public Endpoints (No Auth Required)</a></li>
<li class="toctree-l3"><a class="reference internal" href="AUTHENTICATION.html#protected-endpoints-auth-required">Protected Endpoints (Auth Required)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="AUTHENTICATION.html#authentication-flow">Authentication Flow</a></li>
<li class="toctree-l2"><a class="reference internal" href="AUTHENTICATION.html#error-responses">Error Responses</a><ul>
<li class="toctree-l3"><a class="reference internal" href="AUTHENTICATION.html#unauthorized">401 Unauthorized</a></li>
<li class="toctree-l3"><a class="reference internal" href="AUTHENTICATION.html#rate-limit-exceeded">429 Rate Limit Exceeded</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="AUTHENTICATION.html#rate-limiting">Rate Limiting</a><ul>
<li class="toctree-l3"><a class="reference internal" href="AUTHENTICATION.html#per-key-rate-limits">Per-Key Rate Limits</a></li>
<li class="toctree-l3"><a class="reference internal" href="AUTHENTICATION.html#key-expiration">Key Expiration</a></li>
<li class="toctree-l3"><a class="reference internal" href="AUTHENTICATION.html#hot-reload-api-keys">Hot-Reload API Keys</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="AUTHENTICATION.html#access-logging">Access Logging</a></li>
<li class="toctree-l2"><a class="reference internal" href="AUTHENTICATION.html#metrics">Metrics</a></li>
<li class="toctree-l2"><a class="reference internal" href="AUTHENTICATION.html#deployment-scenarios">Deployment Scenarios</a><ul>
<li class="toctree-l3"><a class="reference internal" href="AUTHENTICATION.html#local-development-auth-disabled">Local Development (Auth Disabled)</a></li>
<li class="toctree-l3"><a class="reference internal" href="AUTHENTICATION.html#local-development-auth-enabled">Local Development (Auth Enabled)</a></li>
<li class="toctree-l3"><a class="reference internal" href="AUTHENTICATION.html#production-secure">Production (Secure)</a></li>
<li class="toctree-l3"><a class="reference internal" href="AUTHENTICATION.html#runpod-serverless">RunPod Serverless</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="AUTHENTICATION.html#security-best-practices">Security Best Practices</a><ul>
<li class="toctree-l3"><a class="reference internal" href="AUTHENTICATION.html#file-security">File Security</a></li>
<li class="toctree-l3"><a class="reference internal" href="AUTHENTICATION.html#key-generation">Key Generation</a></li>
<li class="toctree-l3"><a class="reference internal" href="AUTHENTICATION.html#key-storage">Key Storage</a></li>
<li class="toctree-l3"><a class="reference internal" href="AUTHENTICATION.html#key-rotation">Key Rotation</a></li>
<li class="toctree-l3"><a class="reference internal" href="AUTHENTICATION.html#access-control">Access Control</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="AUTHENTICATION.html#troubleshooting">Troubleshooting</a><ul>
<li class="toctree-l3"><a class="reference internal" href="AUTHENTICATION.html#auth-not-working-all-requests-accepted">Auth Not Working (All Requests Accepted)</a></li>
<li class="toctree-l3"><a class="reference internal" href="AUTHENTICATION.html#valid-key-rejected-401">Valid Key Rejected (401)</a></li>
<li class="toctree-l3"><a class="reference internal" href="AUTHENTICATION.html#rate-limit-issues">Rate Limit Issues</a></li>
<li class="toctree-l3"><a class="reference internal" href="AUTHENTICATION.html#access-logs-not-written">Access Logs Not Written</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="AUTHENTICATION.html#future-enhancements">Future Enhancements</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="CONFIGURATION.html">Configuration Guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="CONFIGURATION.html#environment-variables">Environment Variables</a><ul>
<li class="toctree-l3"><a class="reference internal" href="CONFIGURATION.html#authentication-configuration">Authentication Configuration</a></li>
<li class="toctree-l3"><a class="reference internal" href="CONFIGURATION.html#hot-reload-api-keys">Hot-Reload API Keys</a></li>
<li class="toctree-l3"><a class="reference internal" href="CONFIGURATION.html#cors-configuration">CORS Configuration</a></li>
<li class="toctree-l3"><a class="reference internal" href="CONFIGURATION.html#request-timeouts">Request Timeouts</a></li>
<li class="toctree-l3"><a class="reference internal" href="CONFIGURATION.html#concurrency-control">Concurrency Control</a></li>
<li class="toctree-l3"><a class="reference internal" href="CONFIGURATION.html#security-limits">Security Limits</a></li>
<li class="toctree-l3"><a class="reference internal" href="CONFIGURATION.html#data-directory">Data Directory</a></li>
<li class="toctree-l3"><a class="reference internal" href="CONFIGURATION.html#model-configuration">Model Configuration</a></li>
<li class="toctree-l3"><a class="reference internal" href="CONFIGURATION.html#server-configuration">Server Configuration</a></li>
<li class="toctree-l3"><a class="reference internal" href="CONFIGURATION.html#inference-configuration">Inference Configuration</a></li>
<li class="toctree-l3"><a class="reference internal" href="CONFIGURATION.html#logging-configuration">Logging Configuration</a></li>
<li class="toctree-l3"><a class="reference internal" href="CONFIGURATION.html#debug-configuration">Debug Configuration</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="CONFIGURATION.html#recommended-configurations">Recommended Configurations</a><ul>
<li class="toctree-l3"><a class="reference internal" href="CONFIGURATION.html#rtx-4090-24gb">RTX 4090 (24GB)</a></li>
<li class="toctree-l3"><a class="reference internal" href="CONFIGURATION.html#a100-40gb">A100 (40GB)</a></li>
<li class="toctree-l3"><a class="reference internal" href="CONFIGURATION.html#a100-80gb-h100">A100 (80GB) / H100</a></li>
<li class="toctree-l3"><a class="reference internal" href="CONFIGURATION.html#cpu-only">CPU Only</a></li>
<li class="toctree-l3"><a class="reference internal" href="CONFIGURATION.html#multi-worker-deployment">Multi-Worker Deployment</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="CONFIGURATION.html#memory-estimation">Memory Estimation</a></li>
<li class="toctree-l2"><a class="reference internal" href="CONFIGURATION.html#environment-variable-precedence">Environment Variable Precedence</a></li>
<li class="toctree-l2"><a class="reference internal" href="CONFIGURATION.html#validation">Validation</a></li>
<li class="toctree-l2"><a class="reference internal" href="CONFIGURATION.html#complete-example-configurations">Complete Example Configurations</a><ul>
<li class="toctree-l3"><a class="reference internal" href="CONFIGURATION.html#local-development">Local Development</a></li>
<li class="toctree-l3"><a class="reference internal" href="CONFIGURATION.html#production-runpod-serverless">Production (RunPod Serverless)</a></li>
<li class="toctree-l3"><a class="reference internal" href="CONFIGURATION.html#multi-model-platform">Multi-Model Platform</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="CONFIGURATION.html#security-best-practices">Security Best Practices</a><ul>
<li class="toctree-l3"><a class="reference internal" href="CONFIGURATION.html#api-keys">API Keys</a></li>
<li class="toctree-l3"><a class="reference internal" href="CONFIGURATION.html#network-security">Network Security</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="CONFIGURATION.html#troubleshooting-configuration">Troubleshooting Configuration</a><ul>
<li class="toctree-l3"><a class="reference internal" href="CONFIGURATION.html#check-current-configuration">Check Current Configuration</a></li>
<li class="toctree-l3"><a class="reference internal" href="CONFIGURATION.html#common-issues">Common Issues</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="CONFIGURATION.html#see-also">See Also</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Deployment Guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#runpod-serverless">RunPod Serverless</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#prerequisites">Prerequisites</a></li>
<li class="toctree-l3"><a class="reference internal" href="#quick-start">Quick Start</a></li>
<li class="toctree-l3"><a class="reference internal" href="#scale-to-zero-behavior">Scale-to-Zero Behavior</a></li>
<li class="toctree-l3"><a class="reference internal" href="#api-key-setup">API Key Setup</a></li>
<li class="toctree-l3"><a class="reference internal" href="#testing">Testing</a></li>
<li class="toctree-l3"><a class="reference internal" href="#health-check-verification">Health Check Verification</a></li>
<li class="toctree-l3"><a class="reference internal" href="#common-issues">Common Issues</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#runpod-pods">RunPod Pods</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id1">Prerequisites</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id2">Quick Start</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id3">Health Check Verification</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id4">Common Issues</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#vast-ai">Vast.ai</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id5">Prerequisites</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id6">Quick Start</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id7">Health Check Verification</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id8">Common Issues</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#lambda-labs">Lambda Labs</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id9">Prerequisites</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id10">Quick Start</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id11">Health Check Verification</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id12">Common Issues</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#local-docker-docker-compose">Local Docker / docker-compose</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id13">Prerequisites</a></li>
<li class="toctree-l3"><a class="reference internal" href="#quick-start-gpu">Quick Start (GPU)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#quick-start-cpu">Quick Start (CPU)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#using-docker-compose">Using docker-compose</a></li>
<li class="toctree-l3"><a class="reference internal" href="#environment-variables">Environment Variables</a></li>
<li class="toctree-l3"><a class="reference internal" href="#gpu-passthrough">GPU Passthrough</a></li>
<li class="toctree-l3"><a class="reference internal" href="#volume-mounts">Volume Mounts</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id14">Testing</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id15">Health Check Verification</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id16">Common Issues</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#memory-estimation">Memory Estimation</a></li>
<li class="toctree-l2"><a class="reference internal" href="#see-also">See Also</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="MIGRATION.html">Migration Guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="MIGRATION.html#migrating-from-pre-v1-0-0-to-v1-0-0">Migrating from pre-v1.0.0 to v1.0.0</a><ul>
<li class="toctree-l3"><a class="reference internal" href="MIGRATION.html#environment-variable-changes">Environment Variable Changes</a></li>
<li class="toctree-l3"><a class="reference internal" href="MIGRATION.html#new-features-requiring-configuration">New Features Requiring Configuration</a><ul>
<li class="toctree-l4"><a class="reference internal" href="MIGRATION.html#cors-support">CORS Support</a></li>
<li class="toctree-l4"><a class="reference internal" href="MIGRATION.html#concurrency-control">Concurrency Control</a></li>
<li class="toctree-l4"><a class="reference internal" href="MIGRATION.html#api-key-management-cli">API Key Management CLI</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="MIGRATION.html#docker-image-tag-structure">Docker Image Tag Structure</a></li>
<li class="toctree-l3"><a class="reference internal" href="MIGRATION.html#authentication-changes">Authentication Changes</a></li>
<li class="toctree-l3"><a class="reference internal" href="MIGRATION.html#health-endpoint-changes">Health Endpoint Changes</a></li>
<li class="toctree-l3"><a class="reference internal" href="MIGRATION.html#post-rc-1-features">Post-rc.1 Features</a><ul>
<li class="toctree-l4"><a class="reference internal" href="MIGRATION.html#per-key-rate-limits">Per-Key Rate Limits</a></li>
<li class="toctree-l4"><a class="reference internal" href="MIGRATION.html#key-expiration-ttl">Key Expiration / TTL</a></li>
<li class="toctree-l4"><a class="reference internal" href="MIGRATION.html#hot-reload-api-keys">Hot-Reload API Keys</a></li>
<li class="toctree-l4"><a class="reference internal" href="MIGRATION.html#structured-json-logging">Structured JSON Logging</a></li>
<li class="toctree-l4"><a class="reference internal" href="MIGRATION.html#configurable-timeouts">Configurable Timeouts</a></li>
<li class="toctree-l4"><a class="reference internal" href="MIGRATION.html#non-root-container">Non-Root Container</a></li>
<li class="toctree-l4"><a class="reference internal" href="MIGRATION.html#new-security-limits">New Security Limits</a></li>
<li class="toctree-l4"><a class="reference internal" href="MIGRATION.html#new-http-responses">New HTTP Responses</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="MIGRATION.html#breaking-changes-checklist">Breaking Changes Checklist</a></li>
<li class="toctree-l2"><a class="reference internal" href="MIGRATION.html#new-environment-variables-reference">New Environment Variables Reference</a></li>
<li class="toctree-l2"><a class="reference internal" href="MIGRATION.html#see-also">See Also</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="TESTING.html">Testing Guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="TESTING.html#current-test-coverage">Current Test Coverage</a><ul>
<li class="toctree-l3"><a class="reference internal" href="TESTING.html#pytest-test-suite">pytest Test Suite</a><ul>
<li class="toctree-l4"><a class="reference internal" href="TESTING.html#test-auth-py"><code class="docutils literal notranslate"><span class="pre">test_auth.py</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="TESTING.html#test-gateway-py"><code class="docutils literal notranslate"><span class="pre">test_gateway.py</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="TESTING.html#test-key-mgmt-py"><code class="docutils literal notranslate"><span class="pre">test_key_mgmt.py</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="TESTING.html#test-benchmark-py"><code class="docutils literal notranslate"><span class="pre">test_benchmark.py</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="TESTING.html#shell-tests-pre-commit">Shell Tests (Pre-commit)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="TESTING.html#test-auth-sh"><code class="docutils literal notranslate"><span class="pre">test_auth.sh</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="TESTING.html#test-health-sh"><code class="docutils literal notranslate"><span class="pre">test_health.sh</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="TESTING.html#full-tests-github-actions">Full Tests (GitHub Actions)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="TESTING.html#running-tests">Running Tests</a><ul>
<li class="toctree-l3"><a class="reference internal" href="TESTING.html#manual-testing">Manual Testing</a><ul>
<li class="toctree-l4"><a class="reference internal" href="TESTING.html#test-authentication">Test Authentication</a></li>
<li class="toctree-l4"><a class="reference internal" href="TESTING.html#test-rate-limiting">Test Rate Limiting</a></li>
<li class="toctree-l4"><a class="reference internal" href="TESTING.html#test-logging">Test Logging</a></li>
<li class="toctree-l4"><a class="reference internal" href="TESTING.html#test-worker-type-logging">Test Worker Type Logging</a></li>
<li class="toctree-l4"><a class="reference internal" href="TESTING.html#test-port-naming">Test Port Naming</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="TESTING.html#planned-improvements">Planned Improvements</a></li>
<li class="toctree-l2"><a class="reference internal" href="TESTING.html#debugging-failed-tests">Debugging Failed Tests</a><ul>
<li class="toctree-l3"><a class="reference internal" href="TESTING.html#view-test-logs">View Test Logs</a></li>
<li class="toctree-l3"><a class="reference internal" href="TESTING.html#run-individual-test">Run Individual Test</a></li>
<li class="toctree-l3"><a class="reference internal" href="TESTING.html#debug-auth-issues">Debug Auth Issues</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="TESTING.html#contributing-tests">Contributing Tests</a></li>
<li class="toctree-l2"><a class="reference internal" href="TESTING.html#test-checklist">Test Checklist</a></li>
<li class="toctree-l2"><a class="reference internal" href="TESTING.html#resources">Resources</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="TROUBLESHOOTING.html">Troubleshooting Guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="TROUBLESHOOTING.html#quick-diagnostics">Quick Diagnostics</a><ul>
<li class="toctree-l3"><a class="reference internal" href="TROUBLESHOOTING.html#check-boot-logs">Check boot logs</a></li>
<li class="toctree-l3"><a class="reference internal" href="TROUBLESHOOTING.html#check-server-logs">Check server logs</a></li>
<li class="toctree-l3"><a class="reference internal" href="TROUBLESHOOTING.html#enable-debug-mode">Enable debug mode</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="TROUBLESHOOTING.html#common-issues">Common Issues</a><ul>
<li class="toctree-l3"><a class="reference internal" href="TROUBLESHOOTING.html#model-not-found">Model Not Found</a></li>
<li class="toctree-l3"><a class="reference internal" href="TROUBLESHOOTING.html#out-of-memory-oom">Out of Memory (OOM)</a></li>
<li class="toctree-l3"><a class="reference internal" href="TROUBLESHOOTING.html#server-exits-immediately">Server Exits Immediately</a></li>
<li class="toctree-l3"><a class="reference internal" href="TROUBLESHOOTING.html#gpu-not-detected">GPU Not Detected</a></li>
<li class="toctree-l3"><a class="reference internal" href="TROUBLESHOOTING.html#health-check-failing">Health Check Failing</a></li>
<li class="toctree-l3"><a class="reference internal" href="TROUBLESHOOTING.html#streaming-not-working">Streaming Not Working</a></li>
<li class="toctree-l3"><a class="reference internal" href="TROUBLESHOOTING.html#slow-inference">Slow Inference</a></li>
<li class="toctree-l3"><a class="reference internal" href="TROUBLESHOOTING.html#data-dir-not-found">DATA_DIR Not Found</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="TROUBLESHOOTING.html#log-locations">Log Locations</a></li>
<li class="toctree-l2"><a class="reference internal" href="TROUBLESHOOTING.html#platform-specific-issues">Platform-Specific Issues</a><ul>
<li class="toctree-l3"><a class="reference internal" href="TROUBLESHOOTING.html#runpod-serverless">RunPod Serverless</a></li>
<li class="toctree-l3"><a class="reference internal" href="TROUBLESHOOTING.html#vast-ai">Vast.ai</a></li>
<li class="toctree-l3"><a class="reference internal" href="TROUBLESHOOTING.html#local-docker">Local Docker</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="TROUBLESHOOTING.html#getting-help">Getting Help</a></li>
<li class="toctree-l2"><a class="reference internal" href="TROUBLESHOOTING.html#reporting-issues">Reporting Issues</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Auto-Generated:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="auto/CHANGELOG.html">Changelog</a><ul>
<li class="toctree-l2"><a class="reference internal" href="auto/CHANGELOG.html#unreleased">Unreleased</a><ul>
<li class="toctree-l3"><a class="reference internal" href="auto/CHANGELOG.html#added">Added</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto/CHANGELOG.html#changed">Changed</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto/CHANGELOG.html#security">Security</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="auto/CHANGELOG.html#rc-1-2026-02-13">1.0.0-rc.1 - 2026-02-13</a><ul>
<li class="toctree-l3"><a class="reference internal" href="auto/CHANGELOG.html#id1">Added</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto/CHANGELOG.html#id2">Changed</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto/CHANGELOG.html#fixed">Fixed</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto/CHANGELOG.html#id3">Security</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="auto/ARCHITECTURE_AUTO.html">Architecture (Auto-Generated)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="auto/ARCHITECTURE_AUTO.html#overview">Overview</a><ul>
<li class="toctree-l3"><a class="reference internal" href="auto/ARCHITECTURE_AUTO.html#detected-patterns">Detected Patterns</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="auto/ARCHITECTURE_AUTO.html#flowchart-diagram">Flowchart Diagram</a></li>
<li class="toctree-l2"><a class="reference internal" href="auto/ARCHITECTURE_AUTO.html#state-diagram">State Diagram</a></li>
<li class="toctree-l2"><a class="reference internal" href="auto/ARCHITECTURE_AUTO.html#sequence-diagram">Sequence Diagram</a></li>
<li class="toctree-l2"><a class="reference internal" href="auto/ARCHITECTURE_AUTO.html#architecture-diagram">Architecture Diagram</a></li>
<li class="toctree-l2"><a class="reference internal" href="auto/ARCHITECTURE_AUTO.html#er-diagram">Er Diagram</a></li>
<li class="toctree-l2"><a class="reference internal" href="auto/ARCHITECTURE_AUTO.html#class-diagram">Class Diagram</a></li>
<li class="toctree-l2"><a class="reference internal" href="auto/ARCHITECTURE_AUTO.html#journey-diagram">Journey Diagram</a></li>
<li class="toctree-l2"><a class="reference internal" href="auto/ARCHITECTURE_AUTO.html#mindmap-diagram">Mindmap Diagram</a></li>
<li class="toctree-l2"><a class="reference internal" href="auto/ARCHITECTURE_AUTO.html#workflow-pipeline-diagram">Workflow Pipeline Diagram</a></li>
<li class="toctree-l2"><a class="reference internal" href="auto/ARCHITECTURE_AUTO.html#workflow-triggers-diagram">Workflow Triggers Diagram</a></li>
<li class="toctree-l2"><a class="reference internal" href="auto/ARCHITECTURE_AUTO.html#workflow-jobs-diagram">Workflow Jobs Diagram</a></li>
<li class="toctree-l2"><a class="reference internal" href="auto/ARCHITECTURE_AUTO.html#development-workflows">Development Workflows</a><ul>
<li class="toctree-l3"><a class="reference internal" href="auto/ARCHITECTURE_AUTO.html#github-workflows-summary">GitHub Workflows Summary</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="auto/ARCHITECTURE_AUTO.html#module-summary">Module Summary</a><ul>
<li class="toctree-l3"><a class="reference internal" href="auto/ARCHITECTURE_AUTO.html#docs-conf"><code class="docutils literal notranslate"><span class="pre">docs.conf</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="auto/ARCHITECTURE_AUTO.html#scripts-auth"><code class="docutils literal notranslate"><span class="pre">scripts.auth</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="auto/ARCHITECTURE_AUTO.html#scripts-gateway"><code class="docutils literal notranslate"><span class="pre">scripts.gateway</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="auto/ARCHITECTURE_AUTO.html#scripts-health-server"><code class="docutils literal notranslate"><span class="pre">scripts.health_server</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="auto/ARCHITECTURE_AUTO.html#scripts-key-mgmt"><code class="docutils literal notranslate"><span class="pre">scripts.key_mgmt</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="auto/ARCHITECTURE_AUTO.html#tests-init"><code class="docutils literal notranslate"><span class="pre">tests.__init__</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="auto/ARCHITECTURE_AUTO.html#tests-conftest"><code class="docutils literal notranslate"><span class="pre">tests.conftest</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="auto/ARCHITECTURE_AUTO.html#tests-test-auth"><code class="docutils literal notranslate"><span class="pre">tests.test_auth</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="auto/ARCHITECTURE_AUTO.html#tests-test-gateway"><code class="docutils literal notranslate"><span class="pre">tests.test_gateway</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="auto/ARCHITECTURE_AUTO.html#tests-test-key-mgmt"><code class="docutils literal notranslate"><span class="pre">tests.test_key_mgmt</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="auto/REPO_MAP.html">Repository Structure</a><ul>
<li class="toctree-l2"><a class="reference internal" href="auto/REPO_MAP.html#table-of-contents">Table of Contents</a></li>
<li class="toctree-l2"><a class="reference internal" href="auto/REPO_MAP.html#directory-tree">Directory Tree</a></li>
<li class="toctree-l2"><a class="reference internal" href="auto/REPO_MAP.html#key-files">Key Files</a><ul>
<li class="toctree-l3"><a class="reference internal" href="auto/REPO_MAP.html#entry-points">Entry Points</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto/REPO_MAP.html#important-files">Important Files</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="auto/REPO_MAP.html#configuration-files">Configuration Files</a></li>
<li class="toctree-l2"><a class="reference internal" href="auto/REPO_MAP.html#documentation">Documentation</a></li>
<li class="toctree-l2"><a class="reference internal" href="auto/REPO_MAP.html#scripts">Scripts</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="auto/WORKFLOW_REGISTRY.html">Workflow Registry &amp; Tool Coverage</a><ul>
<li class="toctree-l2"><a class="reference internal" href="auto/WORKFLOW_REGISTRY.html#how-to-use-this-document">How to Use This Document</a></li>
<li class="toctree-l2"><a class="reference internal" href="auto/WORKFLOW_REGISTRY.html#pre-commit-vs-ci-how-they-work-together">Pre-commit vs. CI: How They Work Together</a><ul>
<li class="toctree-l3"><a class="reference internal" href="auto/WORKFLOW_REGISTRY.html#why-the-overlap-matters">Why the overlap matters</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto/WORKFLOW_REGISTRY.html#tools-unique-to-each-context">Tools unique to each context</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="auto/WORKFLOW_REGISTRY.html#workflow-registry">Workflow Registry</a></li>
<li class="toctree-l2"><a class="reference internal" href="auto/WORKFLOW_REGISTRY.html#tool-coverage-matrix">Tool Coverage Matrix</a><ul>
<li class="toctree-l3"><a class="reference internal" href="auto/WORKFLOW_REGISTRY.html#version-comparison-tools-in-both-ci-and-pre-commit">Version Comparison (tools in both CI and pre-commit)</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto/WORKFLOW_REGISTRY.html#scope-differences-between-ci-and-pre-commit">Scope Differences Between CI and Pre-commit</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="auto/WORKFLOW_REGISTRY.html#blocking-vs-advisory-behavior">Blocking vs. Advisory Behavior</a><ul>
<li class="toctree-l3"><a class="reference internal" href="auto/WORKFLOW_REGISTRY.html#blocking-will-fail-your-pr">Blocking (will fail your PR)</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto/WORKFLOW_REGISTRY.html#advisory-warnings-only-will-not-fail">Advisory (warnings only, will not fail)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="auto/WORKFLOW_REGISTRY.html#recommended-adoption-profiles">Recommended Adoption Profiles</a><ul>
<li class="toctree-l3"><a class="reference internal" href="auto/WORKFLOW_REGISTRY.html#python-project-minimal">Python Project (Minimal)</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto/WORKFLOW_REGISTRY.html#python-project-comprehensive">Python Project (Comprehensive)</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto/WORKFLOW_REGISTRY.html#shell-project">Shell Project</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto/WORKFLOW_REGISTRY.html#python-docker-project">Python + Docker Project</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto/WORKFLOW_REGISTRY.html#full-stack-all-workflows">Full Stack (All Workflows)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="auto/WORKFLOW_REGISTRY.html#workflow-version-defaults">Workflow Version Defaults</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">llama-gguf-inference</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Deployment Guide</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/DEPLOYMENT.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="deployment-guide">
<h1>Deployment Guide<a class="headerlink" href="#deployment-guide" title="Link to this heading"></a></h1>
<p>Platform-specific deployment instructions for llama-gguf-inference.</p>
<p>Each section is self-contained. Jump to the platform you are deploying on:</p>
<ul class="simple">
<li><p><a class="reference internal" href="#runpod-serverless"><span class="xref myst">RunPod Serverless</span></a> (primary target)</p></li>
<li><p><a class="reference internal" href="#runpod-pods"><span class="xref myst">RunPod Pods</span></a></p></li>
<li><p><a class="reference internal" href="#vastai"><span class="xref myst">Vast.ai</span></a></p></li>
<li><p><a class="reference internal" href="#lambda-labs"><span class="xref myst">Lambda Labs</span></a></p></li>
<li><p><a class="reference internal" href="#local-docker--docker-compose"><span class="xref myst">Local Docker / docker-compose</span></a></p></li>
</ul>
<hr class="docutils" />
<section id="runpod-serverless">
<h2>RunPod Serverless<a class="headerlink" href="#runpod-serverless" title="Link to this heading"></a></h2>
<p>RunPod Serverless is the primary deployment target. Workers scale to zero when idle, and you pay only for active
inference time.</p>
<section id="prerequisites">
<h3>Prerequisites<a class="headerlink" href="#prerequisites" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p>A RunPod account with GPU credits</p></li>
<li><p>A RunPod Network Volume with your GGUF model file uploaded</p></li>
<li><p>An API keys file uploaded to the network volume (if using authentication)</p></li>
</ul>
</section>
<section id="quick-start">
<h3>Quick Start<a class="headerlink" href="#quick-start" title="Link to this heading"></a></h3>
<ol class="arabic">
<li><p><strong>Create a Network Volume</strong> in the RunPod dashboard and upload your model:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/runpod-volume/
├── models/
│   └── your-model.gguf
└── api_keys.txt
</pre></div>
</div>
</li>
<li><p><strong>Create a Serverless Endpoint</strong> with the following settings:</p>
<ul class="simple">
<li><p><strong>Container Image:</strong> <code class="docutils literal notranslate"><span class="pre">ghcr.io/zepfu/llama-gguf-inference:1.0.0-rc.1</span></code></p></li>
<li><p><strong>Container Disk:</strong> 10 GB (enough for the runtime; model is on the volume)</p></li>
<li><p><strong>Volume:</strong> Attach your Network Volume (mounts at <code class="docutils literal notranslate"><span class="pre">/runpod-volume</span></code>)</p></li>
<li><p><strong>GPU:</strong> Select GPU matching your model size (see <a class="reference internal" href="#memory-estimation"><span class="xref myst">Memory Estimation</span></a>)</p></li>
<li><p><strong>Active Workers:</strong> 0 (enables scale-to-zero)</p></li>
<li><p><strong>Idle Timeout:</strong> 5 seconds (how long to keep a warm worker)</p></li>
<li><p><strong>Exposed Ports:</strong> <code class="docutils literal notranslate"><span class="pre">8000</span></code> (API gateway), <code class="docutils literal notranslate"><span class="pre">8001</span></code> (health checks)</p></li>
<li><p><strong>Health Check Port:</strong> <code class="docutils literal notranslate"><span class="pre">8001</span></code></p></li>
</ul>
</li>
<li><p><strong>Set environment variables</strong> in the endpoint configuration:</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Variable</p></th>
<th class="head"><p>Value</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">MODEL_NAME</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">your-model.gguf</span></code></p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">AUTH_ENABLED</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">true</span></code></p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">AUTH_KEYS_FILE</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">/runpod-volume/api_keys.txt</span></code></p></td>
<td><p>No</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">PORT_HEALTH</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">8001</span></code></p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">NGL</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">99</span></code></p></td>
<td><p>No</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">CTX</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">16384</span></code></p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">MAX_REQUESTS_PER_MINUTE</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">100</span></code></p></td>
<td><p>No</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">MAX_CONCURRENT_REQUESTS</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">1</span></code></p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</li>
</ol>
</section>
<section id="scale-to-zero-behavior">
<h3>Scale-to-Zero Behavior<a class="headerlink" href="#scale-to-zero-behavior" title="Link to this heading"></a></h3>
<p>The container exposes two ports to support scale-to-zero:</p>
<ul class="simple">
<li><p><strong>Port 8001</strong> (health server) — A minimal HTTP server that responds to platform health checks without touching the
llama-server backend. RunPod uses this to determine if the worker is alive.</p></li>
<li><p><strong>Port 8000</strong> (gateway) — The API gateway that handles authenticated requests, CORS, and request queuing.</p></li>
</ul>
<p>Configure RunPod to health-check on port 8001. This ensures that health probes do not keep the worker active when there
are no real API requests.</p>
</section>
<section id="api-key-setup">
<h3>API Key Setup<a class="headerlink" href="#api-key-setup" title="Link to this heading"></a></h3>
<p>Upload your API keys file to the network volume before starting the endpoint:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># Generate a key</span>
python3<span class="w"> </span>scripts/key_mgmt.py<span class="w"> </span>generate<span class="w"> </span>--name<span class="w"> </span>production<span class="w"> </span>--file<span class="w"> </span>api_keys.txt

<span class="c1"># Upload to volume (via RunPod file browser or SSH)</span>
<span class="c1"># Place at: /runpod-volume/api_keys.txt</span>
</pre></div>
</div>
</section>
<section id="testing">
<h3>Testing<a class="headerlink" href="#testing" title="Link to this heading"></a></h3>
<p><strong>With <code class="docutils literal notranslate"><span class="pre">curl</span></code>:</strong></p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># Health check (no auth required)</span>
curl<span class="w"> </span>https://your-endpoint-id-runpod.io/health

<span class="c1"># Chat completion</span>
curl<span class="w"> </span>https://your-endpoint-id-runpod.io/v1/chat/completions<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-H<span class="w"> </span><span class="s2">&quot;Authorization: Bearer YOUR_API_KEY&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-H<span class="w"> </span><span class="s2">&quot;Content-Type: application/json&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-d<span class="w"> </span><span class="s1">&#39;{</span>
<span class="s1">    &quot;model&quot;: &quot;any&quot;,</span>
<span class="s1">    &quot;messages&quot;: [{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Hello!&quot;}]</span>
<span class="s1">  }&#39;</span>
</pre></div>
</div>
<p><strong>With the OpenAI Python SDK:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">openai</span><span class="w"> </span><span class="kn">import</span> <span class="n">OpenAI</span>

<span class="n">client</span> <span class="o">=</span> <span class="n">OpenAI</span><span class="p">(</span>
    <span class="n">api_key</span><span class="o">=</span><span class="s2">&quot;YOUR_API_KEY&quot;</span><span class="p">,</span>
    <span class="n">base_url</span><span class="o">=</span><span class="s2">&quot;https://your-endpoint-id-runpod.io/v1&quot;</span>
<span class="p">)</span>

<span class="n">response</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="s2">&quot;any&quot;</span><span class="p">,</span>
    <span class="n">messages</span><span class="o">=</span><span class="p">[{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;Hello!&quot;</span><span class="p">}]</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">content</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="health-check-verification">
<h3>Health Check Verification<a class="headerlink" href="#health-check-verification" title="Link to this heading"></a></h3>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># Should return 200 with status JSON when model is loaded</span>
curl<span class="w"> </span>-s<span class="w"> </span>https://your-endpoint-id-runpod.io/health<span class="w"> </span><span class="p">|</span><span class="w"> </span>python3<span class="w"> </span>-m<span class="w"> </span>json.tool

<span class="c1"># Quick ping (returns 200 with empty body when ready, 204 when initializing)</span>
curl<span class="w"> </span>-s<span class="w"> </span>-o<span class="w"> </span>/dev/null<span class="w"> </span>-w<span class="w"> </span><span class="s2">&quot;%{http_code}&quot;</span><span class="w"> </span>https://your-endpoint-id-runpod.io/ping
</pre></div>
</div>
</section>
<section id="common-issues">
<h3>Common Issues<a class="headerlink" href="#common-issues" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p><strong>Worker stuck in “Initializing”:</strong> Large models take time to load. Check the boot log at
<code class="docutils literal notranslate"><span class="pre">/runpod-volume/logs/_boot/latest.txt</span></code>. Increase the startup timeout in RunPod settings if needed.</p></li>
<li><p><strong>HuggingFace validation stuck:</strong> This is a RunPod/HF platform issue. Use a placeholder value in the HF repo field or
wait for HF to recover.</p></li>
<li><p><strong>Model not found:</strong> Ensure the model file is in <code class="docutils literal notranslate"><span class="pre">/runpod-volume/models/</span></code> and the <code class="docutils literal notranslate"><span class="pre">MODEL_NAME</span></code> matches exactly
(case-sensitive).</p></li>
</ul>
</section>
</section>
<hr class="docutils" />
<section id="runpod-pods">
<h2>RunPod Pods<a class="headerlink" href="#runpod-pods" title="Link to this heading"></a></h2>
<p>RunPod Pods are persistent GPU instances. Unlike Serverless, Pods stay running and you pay for the full uptime.</p>
<section id="id1">
<h3>Prerequisites<a class="headerlink" href="#id1" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p>A RunPod account with GPU credits</p></li>
<li><p>A Pod with a GPU matching your model size</p></li>
</ul>
</section>
<section id="id2">
<h3>Quick Start<a class="headerlink" href="#id2" title="Link to this heading"></a></h3>
<ol class="arabic">
<li><p><strong>Create a Pod</strong> in the RunPod dashboard:</p>
<ul class="simple">
<li><p><strong>Container Image:</strong> <code class="docutils literal notranslate"><span class="pre">ghcr.io/zepfu/llama-gguf-inference:1.0.0-rc.1</span></code></p></li>
<li><p><strong>GPU:</strong> Select based on your model size</p></li>
<li><p><strong>Volume:</strong> Allocate disk for models (or attach a Network Volume)</p></li>
<li><p><strong>Exposed Ports:</strong> <code class="docutils literal notranslate"><span class="pre">8000</span></code> (gateway), <code class="docutils literal notranslate"><span class="pre">8001</span></code> (health)</p></li>
</ul>
</li>
<li><p><strong>Upload your model</strong> to the pod volume:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/workspace/
├── models/
│   └── your-model.gguf
└── api_keys.txt
</pre></div>
</div>
</li>
<li><p><strong>Set environment variables:</strong></p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Variable</p></th>
<th class="head"><p>Value</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">MODEL_NAME</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">your-model.gguf</span></code></p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">AUTH_ENABLED</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">true</span></code></p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">AUTH_KEYS_FILE</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">/workspace/api_keys.txt</span></code></p></td>
<td><p>No</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">NGL</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">99</span></code></p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">CTX</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">16384</span></code></p></td>
<td><p>No</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">MAX_REQUESTS_PER_MINUTE</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">100</span></code></p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</li>
</ol>
<p>The container auto-detects <code class="docutils literal notranslate"><span class="pre">/workspace</span></code> and uses it as the data directory.</p>
</section>
<section id="id3">
<h3>Health Check Verification<a class="headerlink" href="#id3" title="Link to this heading"></a></h3>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>curl<span class="w"> </span>-s<span class="w"> </span>http://YOUR_POD_IP:8000/health<span class="w"> </span><span class="p">|</span><span class="w"> </span>python3<span class="w"> </span>-m<span class="w"> </span>json.tool
</pre></div>
</div>
</section>
<section id="id4">
<h3>Common Issues<a class="headerlink" href="#id4" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p><strong>Volume not mounted:</strong> Ensure the pod has a volume attached. Check that <code class="docutils literal notranslate"><span class="pre">/workspace</span></code> exists and contains your model.</p></li>
<li><p><strong>Port not exposed:</strong> Verify both ports 8000 and 8001 are listed in the pod’s exposed ports.</p></li>
</ul>
</section>
</section>
<hr class="docutils" />
<section id="vast-ai">
<h2>Vast.ai<a class="headerlink" href="#vast-ai" title="Link to this heading"></a></h2>
<p>Vast.ai provides competitive GPU pricing with Docker-based deployments.</p>
<section id="id5">
<h3>Prerequisites<a class="headerlink" href="#id5" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p>A Vast.ai account with credits</p></li>
<li><p>A GPU instance matching your model size</p></li>
</ul>
</section>
<section id="id6">
<h3>Quick Start<a class="headerlink" href="#id6" title="Link to this heading"></a></h3>
<ol class="arabic">
<li><p><strong>Create an instance</strong> on Vast.ai:</p>
<ul class="simple">
<li><p><strong>Docker Image:</strong> <code class="docutils literal notranslate"><span class="pre">ghcr.io/zepfu/llama-gguf-inference:1.0.0-rc.1</span></code></p></li>
<li><p><strong>GPU:</strong> Select based on your model size</p></li>
<li><p><strong>Disk:</strong> Allocate enough for your model file</p></li>
<li><p><strong>Exposed Ports:</strong> <code class="docutils literal notranslate"><span class="pre">8000</span></code>, <code class="docutils literal notranslate"><span class="pre">8001</span></code></p></li>
</ul>
</li>
<li><p><strong>Pull the image</strong> (if not automatic):</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>docker<span class="w"> </span>pull<span class="w"> </span>ghcr.io/zepfu/llama-gguf-inference:1.0.0-rc.1
</pre></div>
</div>
</li>
<li><p><strong>Upload your model</strong> to the instance volume:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/workspace/
├── models/
│   └── your-model.gguf
└── api_keys.txt
</pre></div>
</div>
</li>
<li><p><strong>Set environment variables</strong> in the instance configuration:</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Variable</p></th>
<th class="head"><p>Value</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">MODEL_NAME</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">your-model.gguf</span></code></p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">AUTH_ENABLED</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">true</span></code></p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">AUTH_KEYS_FILE</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">/workspace/api_keys.txt</span></code></p></td>
<td><p>No</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">NGL</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">99</span></code></p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">CTX</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">16384</span></code></p></td>
<td><p>No</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">MAX_REQUESTS_PER_MINUTE</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">100</span></code></p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</li>
</ol>
<p>The container auto-detects <code class="docutils literal notranslate"><span class="pre">/workspace</span></code> and uses it as the data directory.</p>
</section>
<section id="id7">
<h3>Health Check Verification<a class="headerlink" href="#id7" title="Link to this heading"></a></h3>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># Replace YOUR_INSTANCE_IP and mapped port</span>
curl<span class="w"> </span>-s<span class="w"> </span>http://YOUR_INSTANCE_IP:8000/health<span class="w"> </span><span class="p">|</span><span class="w"> </span>python3<span class="w"> </span>-m<span class="w"> </span>json.tool
</pre></div>
</div>
</section>
<section id="id8">
<h3>Common Issues<a class="headerlink" href="#id8" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p><strong>Volume not mounted:</strong> Ensure the instance has disk allocated. Check that <code class="docutils literal notranslate"><span class="pre">/workspace</span></code> exists.</p></li>
<li><p><strong>Port mapping:</strong> Vast.ai maps container ports to random host ports. Use the Vast.ai dashboard to find the mapped port
numbers for 8000 and 8001.</p></li>
<li><p><strong>Model not found:</strong> Upload the model to <code class="docutils literal notranslate"><span class="pre">/workspace/models/</span></code> and verify the filename matches <code class="docutils literal notranslate"><span class="pre">MODEL_NAME</span></code> exactly.</p></li>
</ul>
</section>
</section>
<hr class="docutils" />
<section id="lambda-labs">
<h2>Lambda Labs<a class="headerlink" href="#lambda-labs" title="Link to this heading"></a></h2>
<p>Lambda Labs provides on-demand GPU cloud instances with Docker support.</p>
<section id="id9">
<h3>Prerequisites<a class="headerlink" href="#id9" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p>A Lambda Labs account</p></li>
<li><p>An instance with a GPU (A10, A100, H100, etc.)</p></li>
<li><p>Docker installed on the instance (pre-installed on Lambda Cloud instances)</p></li>
</ul>
</section>
<section id="id10">
<h3>Quick Start<a class="headerlink" href="#id10" title="Link to this heading"></a></h3>
<ol class="arabic">
<li><p><strong>Launch a Lambda instance</strong> with Docker pre-installed.</p></li>
<li><p><strong>Pull the image:</strong></p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>docker<span class="w"> </span>pull<span class="w"> </span>ghcr.io/zepfu/llama-gguf-inference:1.0.0-rc.1
</pre></div>
</div>
</li>
<li><p><strong>Prepare your data directory:</strong></p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>mkdir<span class="w"> </span>-p<span class="w"> </span>/data/models
<span class="c1"># Copy or download your model</span>
cp<span class="w"> </span>your-model.gguf<span class="w"> </span>/data/models/

<span class="c1"># Create API keys file (optional)</span>
python3<span class="w"> </span>scripts/key_mgmt.py<span class="w"> </span>generate<span class="w"> </span>--name<span class="w"> </span>production<span class="w"> </span>--file<span class="w"> </span>/data/api_keys.txt
</pre></div>
</div>
</li>
<li><p><strong>Run the container:</strong></p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>docker<span class="w"> </span>run<span class="w"> </span>--gpus<span class="w"> </span>all<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-v<span class="w"> </span>/data:/data<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-e<span class="w"> </span><span class="nv">MODEL_NAME</span><span class="o">=</span>your-model.gguf<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-e<span class="w"> </span><span class="nv">AUTH_ENABLED</span><span class="o">=</span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-e<span class="w"> </span><span class="nv">AUTH_KEYS_FILE</span><span class="o">=</span>/data/api_keys.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-p<span class="w"> </span><span class="m">8000</span>:8000<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-p<span class="w"> </span><span class="m">8001</span>:8001<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>ghcr.io/zepfu/llama-gguf-inference:1.0.0-rc.1
</pre></div>
</div>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Variable</p></th>
<th class="head"><p>Value</p></th>
<th class="head"><p>Required</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">MODEL_NAME</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">your-model.gguf</span></code></p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">AUTH_ENABLED</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">true</span></code></p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">AUTH_KEYS_FILE</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">/data/api_keys.txt</span></code></p></td>
<td><p>No</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">NGL</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">99</span></code></p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">CTX</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">16384</span></code></p></td>
<td><p>No</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">DATA_DIR</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">/data</span></code></p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">MAX_REQUESTS_PER_MINUTE</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">100</span></code></p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</li>
</ol>
<p>GPU detection works automatically on Lambda instances — no additional configuration needed.</p>
</section>
<section id="id11">
<h3>Health Check Verification<a class="headerlink" href="#id11" title="Link to this heading"></a></h3>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>curl<span class="w"> </span>-s<span class="w"> </span>http://localhost:8000/health<span class="w"> </span><span class="p">|</span><span class="w"> </span>python3<span class="w"> </span>-m<span class="w"> </span>json.tool
</pre></div>
</div>
</section>
<section id="id12">
<h3>Common Issues<a class="headerlink" href="#id12" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p><strong>Docker GPU access:</strong> Ensure <code class="docutils literal notranslate"><span class="pre">nvidia-container-toolkit</span></code> is installed. Lambda Cloud instances have this pre-installed.
Verify with <code class="docutils literal notranslate"><span class="pre">docker</span> <span class="pre">run</span> <span class="pre">--gpus</span> <span class="pre">all</span> <span class="pre">nvidia/cuda:12.0-base</span> <span class="pre">nvidia-smi</span></code>.</p></li>
<li><p><strong>Firewall:</strong> Lambda instances may require you to open ports 8000 and 8001 in the firewall or security group settings.</p></li>
</ul>
</section>
</section>
<hr class="docutils" />
<section id="local-docker-docker-compose">
<h2>Local Docker / docker-compose<a class="headerlink" href="#local-docker-docker-compose" title="Link to this heading"></a></h2>
<p>Run llama-gguf-inference on your local machine or any Docker host.</p>
<section id="id13">
<h3>Prerequisites<a class="headerlink" href="#id13" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p>Docker installed (<a class="reference external" href="https://docs.docker.com/get-docker/">Install Docker</a>)</p></li>
<li><p>For GPU: NVIDIA GPU with drivers installed and
<a class="reference external" href="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html">nvidia-container-toolkit</a></p></li>
<li><p>A GGUF model file</p></li>
</ul>
</section>
<section id="quick-start-gpu">
<h3>Quick Start (GPU)<a class="headerlink" href="#quick-start-gpu" title="Link to this heading"></a></h3>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># Pull the image</span>
docker<span class="w"> </span>pull<span class="w"> </span>ghcr.io/zepfu/llama-gguf-inference:1.0.0-rc.1

<span class="c1"># Prepare data directory</span>
mkdir<span class="w"> </span>-p<span class="w"> </span>./data/models
cp<span class="w"> </span>your-model.gguf<span class="w"> </span>./data/models/

<span class="c1"># Create API keys file</span>
cat<span class="w"> </span>&gt;<span class="w"> </span>./data/api_keys.txt<span class="w"> </span><span class="s">&lt;&lt; EOF</span>
<span class="s">production:sk-prod-$(openssl rand -hex 32)</span>
<span class="s">EOF</span>
chmod<span class="w"> </span><span class="m">600</span><span class="w"> </span>./data/api_keys.txt

<span class="c1"># Run with GPU</span>
docker<span class="w"> </span>run<span class="w"> </span>--gpus<span class="w"> </span>all<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-v<span class="w"> </span><span class="k">$(</span><span class="nb">pwd</span><span class="k">)</span>/data:/data<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-e<span class="w"> </span><span class="nv">MODEL_NAME</span><span class="o">=</span>your-model.gguf<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-e<span class="w"> </span><span class="nv">AUTH_ENABLED</span><span class="o">=</span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-p<span class="w"> </span><span class="m">8000</span>:8000<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-p<span class="w"> </span><span class="m">8001</span>:8001<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>ghcr.io/zepfu/llama-gguf-inference:1.0.0-rc.1
</pre></div>
</div>
</section>
<section id="quick-start-cpu">
<h3>Quick Start (CPU)<a class="headerlink" href="#quick-start-cpu" title="Link to this heading"></a></h3>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># Pull the CPU image</span>
docker<span class="w"> </span>pull<span class="w"> </span>ghcr.io/zepfu/llama-gguf-inference:cpu-1.0.0-rc.1

<span class="c1"># Run without GPU</span>
docker<span class="w"> </span>run<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-v<span class="w"> </span><span class="k">$(</span><span class="nb">pwd</span><span class="k">)</span>/data:/data<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-e<span class="w"> </span><span class="nv">MODEL_NAME</span><span class="o">=</span>your-model.gguf<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-e<span class="w"> </span><span class="nv">AUTH_ENABLED</span><span class="o">=</span><span class="nb">false</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-e<span class="w"> </span><span class="nv">NGL</span><span class="o">=</span><span class="m">0</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-e<span class="w"> </span><span class="nv">CTX</span><span class="o">=</span><span class="m">4096</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-p<span class="w"> </span><span class="m">8000</span>:8000<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-p<span class="w"> </span><span class="m">8001</span>:8001<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>ghcr.io/zepfu/llama-gguf-inference:cpu-1.0.0-rc.1
</pre></div>
</div>
</section>
<section id="using-docker-compose">
<h3>Using docker-compose<a class="headerlink" href="#using-docker-compose" title="Link to this heading"></a></h3>
<p>A <code class="docutils literal notranslate"><span class="pre">docker-compose.yml</span></code> is included in the repository with GPU and CPU service definitions:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># GPU service</span>
docker<span class="w"> </span>compose<span class="w"> </span>up<span class="w"> </span>inference-gpu

<span class="c1"># CPU service</span>
docker<span class="w"> </span>compose<span class="w"> </span>up<span class="w"> </span>inference-cpu
</pre></div>
</div>
<p>Before starting, update the <code class="docutils literal notranslate"><span class="pre">docker-compose.yml</span></code> environment variables:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">environment</span><span class="p">:</span>
<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">MODEL_NAME=your-model.gguf</span><span class="w">    </span><span class="c1"># Set to your model filename</span>
<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">AUTH_ENABLED=true</span>
<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">AUTH_KEYS_FILE=/data/api_keys.txt</span>
</pre></div>
</div>
<p>Place your model and keys file in the <code class="docutils literal notranslate"><span class="pre">./data/</span></code> directory:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>./data/
├── models/
│   └── your-model.gguf
└── api_keys.txt
</pre></div>
</div>
</section>
<section id="environment-variables">
<h3>Environment Variables<a class="headerlink" href="#environment-variables" title="Link to this heading"></a></h3>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Variable</p></th>
<th class="head"><p>Default</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">MODEL_NAME</span></code></p></td>
<td><p>—</p></td>
<td><p>Model filename in <code class="docutils literal notranslate"><span class="pre">DATA_DIR/models/</span></code> (required)</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">AUTH_ENABLED</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">true</span></code></p></td>
<td><p>Enable API key authentication</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">AUTH_KEYS_FILE</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">$DATA_DIR/api_keys.txt</span></code></p></td>
<td><p>Path to API keys file</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">NGL</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">99</span></code></p></td>
<td><p>GPU layers (99 = all, 0 = CPU only)</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">CTX</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">16384</span></code></p></td>
<td><p>Context length</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">DATA_DIR</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">/data</span></code></p></td>
<td><p>Base directory for models and logs</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">PORT</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">8000</span></code></p></td>
<td><p>Gateway port</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">PORT_HEALTH</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">8001</span></code></p></td>
<td><p>Health check port</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">PORT_BACKEND</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">8080</span></code></p></td>
<td><p>Internal llama-server port</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">MAX_CONCURRENT_REQUESTS</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">1</span></code></p></td>
<td><p>Max simultaneous backend requests</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">MAX_QUEUE_SIZE</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">0</span></code></p></td>
<td><p>Max queued requests (0 = unlimited)</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">MAX_REQUESTS_PER_MINUTE</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">100</span></code></p></td>
<td><p>Rate limit per API key</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">CORS_ORIGINS</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">&quot;&quot;</span></code></p></td>
<td><p>Comma-separated allowed CORS origins</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">WORKER_TYPE</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">&quot;&quot;</span></code></p></td>
<td><p>Worker classification for log organization</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">THREADS</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">0</span></code></p></td>
<td><p>CPU threads (0 = auto-detect)</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">EXTRA_ARGS</span></code></p></td>
<td><p>—</p></td>
<td><p>Additional llama-server arguments</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">DEBUG_SHELL</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">false</span></code></p></td>
<td><p>Hold container for debugging</p></td>
</tr>
</tbody>
</table>
<p>For the complete reference, see <a class="reference internal" href="CONFIGURATION.html"><span class="std std-doc">CONFIGURATION.md</span></a>.</p>
</section>
<section id="gpu-passthrough">
<h3>GPU Passthrough<a class="headerlink" href="#gpu-passthrough" title="Link to this heading"></a></h3>
<p>For NVIDIA GPUs, use the <code class="docutils literal notranslate"><span class="pre">--gpus</span></code> flag:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># All GPUs</span>
docker<span class="w"> </span>run<span class="w"> </span>--gpus<span class="w"> </span>all<span class="w"> </span>...

<span class="c1"># Specific GPU</span>
docker<span class="w"> </span>run<span class="w"> </span>--gpus<span class="w"> </span><span class="s1">&#39;&quot;device=0&quot;&#39;</span><span class="w"> </span>...
</pre></div>
</div>
<p>Verify GPU access inside the container:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>docker<span class="w"> </span>run<span class="w"> </span>--gpus<span class="w"> </span>all<span class="w"> </span>ghcr.io/zepfu/llama-gguf-inference:1.0.0-rc.1<span class="w"> </span>nvidia-smi
</pre></div>
</div>
<p>If <code class="docutils literal notranslate"><span class="pre">nvidia-smi</span></code> is not found, install
<a class="reference external" href="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html">nvidia-container-toolkit</a>.</p>
</section>
<section id="volume-mounts">
<h3>Volume Mounts<a class="headerlink" href="#volume-mounts" title="Link to this heading"></a></h3>
<p>Mount your data directory into the container at <code class="docutils literal notranslate"><span class="pre">/data</span></code>:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>-v<span class="w"> </span>/path/to/your/data:/data
</pre></div>
</div>
<p>Directory structure inside the volume:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/data/
├── models/           # Place your .gguf files here
│   └── model.gguf
├── api_keys.txt      # API keys (if AUTH_ENABLED=true)
└── logs/             # Created automatically at runtime
    ├── _boot/
    └── llama/
</pre></div>
</div>
<p>For read-only API keys (recommended for production):</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>-v<span class="w"> </span>/path/to/api_keys.txt:/data/api_keys.txt:ro
</pre></div>
</div>
</section>
<section id="id14">
<h3>Testing<a class="headerlink" href="#id14" title="Link to this heading"></a></h3>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># Health check</span>
curl<span class="w"> </span>http://localhost:8000/ping

<span class="c1"># Detailed health status</span>
curl<span class="w"> </span>-s<span class="w"> </span>http://localhost:8000/health<span class="w"> </span><span class="p">|</span><span class="w"> </span>python3<span class="w"> </span>-m<span class="w"> </span>json.tool

<span class="c1"># Chat completion (with auth)</span>
curl<span class="w"> </span>http://localhost:8000/v1/chat/completions<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-H<span class="w"> </span><span class="s2">&quot;Authorization: Bearer YOUR_API_KEY&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-H<span class="w"> </span><span class="s2">&quot;Content-Type: application/json&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-d<span class="w"> </span><span class="s1">&#39;{</span>
<span class="s1">    &quot;model&quot;: &quot;any&quot;,</span>
<span class="s1">    &quot;messages&quot;: [{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Hello!&quot;}]</span>
<span class="s1">  }&#39;</span>

<span class="c1"># Chat completion (auth disabled)</span>
curl<span class="w"> </span>http://localhost:8000/v1/chat/completions<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-H<span class="w"> </span><span class="s2">&quot;Content-Type: application/json&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-d<span class="w"> </span><span class="s1">&#39;{</span>
<span class="s1">    &quot;model&quot;: &quot;any&quot;,</span>
<span class="s1">    &quot;messages&quot;: [{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Hello!&quot;}]</span>
<span class="s1">  }&#39;</span>

<span class="c1"># List models</span>
curl<span class="w"> </span>-H<span class="w"> </span><span class="s2">&quot;Authorization: Bearer YOUR_API_KEY&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>http://localhost:8000/v1/models

<span class="c1"># Streaming</span>
curl<span class="w"> </span>http://localhost:8000/v1/chat/completions<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-H<span class="w"> </span><span class="s2">&quot;Authorization: Bearer YOUR_API_KEY&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-H<span class="w"> </span><span class="s2">&quot;Content-Type: application/json&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-d<span class="w"> </span><span class="s1">&#39;{</span>
<span class="s1">    &quot;model&quot;: &quot;any&quot;,</span>
<span class="s1">    &quot;stream&quot;: true,</span>
<span class="s1">    &quot;messages&quot;: [{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Hello!&quot;}]</span>
<span class="s1">  }&#39;</span>
</pre></div>
</div>
</section>
<section id="id15">
<h3>Health Check Verification<a class="headerlink" href="#id15" title="Link to this heading"></a></h3>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># Quick ping (200 = ready, 204 = initializing)</span>
curl<span class="w"> </span>-s<span class="w"> </span>-o<span class="w"> </span>/dev/null<span class="w"> </span>-w<span class="w"> </span><span class="s2">&quot;%{http_code}&quot;</span><span class="w"> </span>http://localhost:8000/ping

<span class="c1"># Full status</span>
curl<span class="w"> </span>-s<span class="w"> </span>http://localhost:8000/health<span class="w"> </span><span class="p">|</span><span class="w"> </span>python3<span class="w"> </span>-m<span class="w"> </span>json.tool

<span class="c1"># Metrics</span>
curl<span class="w"> </span>-s<span class="w"> </span>http://localhost:8000/metrics<span class="w"> </span><span class="p">|</span><span class="w"> </span>python3<span class="w"> </span>-m<span class="w"> </span>json.tool
</pre></div>
</div>
</section>
<section id="id16">
<h3>Common Issues<a class="headerlink" href="#id16" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p><strong>GPU not detected:</strong> Ensure <code class="docutils literal notranslate"><span class="pre">--gpus</span> <span class="pre">all</span></code> is passed and nvidia-container-toolkit is installed. Test with
<code class="docutils literal notranslate"><span class="pre">docker</span> <span class="pre">run</span> <span class="pre">--gpus</span> <span class="pre">all</span> <span class="pre">nvidia/cuda:12.0-base</span> <span class="pre">nvidia-smi</span></code>.</p></li>
<li><p><strong>Model not found:</strong> Check that the model file is in <code class="docutils literal notranslate"><span class="pre">./data/models/</span></code> and <code class="docutils literal notranslate"><span class="pre">MODEL_NAME</span></code> matches exactly
(case-sensitive). Run <code class="docutils literal notranslate"><span class="pre">ls</span> <span class="pre">-la</span> <span class="pre">./data/models/</span></code> to verify.</p></li>
<li><p><strong>Permission denied:</strong> Ensure the data directory is readable. Run <code class="docutils literal notranslate"><span class="pre">chmod</span> <span class="pre">-R</span> <span class="pre">755</span> <span class="pre">./data/</span></code> if needed.</p></li>
<li><p><strong>Port already in use:</strong> Change the host port mapping: <code class="docutils literal notranslate"><span class="pre">-p</span> <span class="pre">9000:8000</span></code> instead of <code class="docutils literal notranslate"><span class="pre">-p</span> <span class="pre">8000:8000</span></code>.</p></li>
<li><p><strong>Out of memory:</strong> Reduce <code class="docutils literal notranslate"><span class="pre">NGL</span></code> for partial GPU offload or reduce <code class="docutils literal notranslate"><span class="pre">CTX</span></code>. See <a class="reference internal" href="TROUBLESHOOTING.html"><span class="std std-doc">TROUBLESHOOTING.md</span></a>
for memory estimation tables.</p></li>
</ul>
</section>
</section>
<hr class="docutils" />
<section id="memory-estimation">
<h2>Memory Estimation<a class="headerlink" href="#memory-estimation" title="Link to this heading"></a></h2>
<p>Use this table to select the right GPU for your model. Values are approximate for Q4 quantized models:</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Model Size</p></th>
<th class="head"><p>VRAM (full offload)</p></th>
<th class="head"><p>Recommended GPU</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>7B</p></td>
<td><p>~4-5 GB</p></td>
<td><p>RTX 3060+, T4, any cloud</p></td>
</tr>
<tr class="row-odd"><td><p>13B</p></td>
<td><p>~8-9 GB</p></td>
<td><p>RTX 3080+, T4, L4</p></td>
</tr>
<tr class="row-even"><td><p>30B</p></td>
<td><p>~18-20 GB</p></td>
<td><p>RTX 4090, A10, L40</p></td>
</tr>
<tr class="row-odd"><td><p>70B</p></td>
<td><p>~40+ GB</p></td>
<td><p>A100 40GB+, H100</p></td>
</tr>
</tbody>
</table>
<p>Additional VRAM overhead: ~0.5 GB per 8K context length, plus ~0.5 GB for compute buffers.</p>
</section>
<hr class="docutils" />
<section id="see-also">
<h2>See Also<a class="headerlink" href="#see-also" title="Link to this heading"></a></h2>
<ul class="simple">
<li><p><a class="reference internal" href="CONFIGURATION.html"><span class="std std-doc">CONFIGURATION.md</span></a> — Full environment variable reference</p></li>
<li><p><a class="reference internal" href="AUTHENTICATION.html"><span class="std std-doc">AUTHENTICATION.md</span></a> — Authentication setup and key management</p></li>
<li><p><a class="reference internal" href="MIGRATION.html"><span class="std std-doc">MIGRATION.md</span></a> — Upgrade guide and breaking changes</p></li>
<li><p><a class="reference internal" href="TROUBLESHOOTING.html"><span class="std std-doc">TROUBLESHOOTING.md</span></a> — Diagnosing common issues</p></li>
</ul>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="CONFIGURATION.html" class="btn btn-neutral float-left" title="Configuration Guide" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="MIGRATION.html" class="btn btn-neutral float-right" title="Migration Guide" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, llama-gguf-inference contributors.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>